# Abstract
### Music plays a crucial role in human emotions, influencing mood, behaviour, and even physiological responses. This project aims to develop a music emotion classification system capable of recognizing and categorizing emotions in music while also modifying emotional tone through tonality-based transposition. The goal is to enhance human-music interaction by classifying the emotional impact of songs and altering their tonality to achieve a different emotional expression. Using the EMOPIA and DEAM datasets, we will train machine learning models from scratch, progressing from basic classification techniques like K-Nearest Neighbours (KNN) to more advanced deep learning models such as LSTM (Long Short-Term Memory). Additionally, we use the Librosa library for feature extraction and music processing, ensuring accurate identification of key musical characteristics that contribute to emotion perception. The final product will be an interactive web application allowing users to dynamically analyze and manipulate music emotions.
![image](https://github.com/user-attachments/assets/460cec1a-830b-4e70-9219-d9914c00aa30)
